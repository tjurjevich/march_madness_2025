{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-17 18:09:26.671405: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import setuptools.dist\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "import optuna\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TRAIN_SIZE = 0.7\n",
    "\n",
    "data = pl.read_parquet(\"model_data.parquet\")\n",
    "\n",
    "# Filter data to two groups: pre-2025 NCAA tournament games OR 2025 games\n",
    "data = data.filter((pl.col(\"NCAATourneyFlag_A\")==1)|(pl.col(\"Season\")==2025))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target variable\n",
    "- WinFlag_A\n",
    "\n",
    "## Categorical variables (one hot encode)\n",
    "- GameLocation\n",
    "- TeamConf (A & B)\n",
    "- CoachName (A & B)\n",
    "- TeamID (A & B)\n",
    "- Season\n",
    "\n",
    "## Categorical variables (leave alone)\n",
    "- RegSeasonFlag_A\n",
    "- ConfTourneyFlag_A\n",
    "- NCAATourneyFlag_A\n",
    "\n",
    "## Numeric variables (standardize)\n",
    "- ActiveTourneyWins_School (A & B)\n",
    "- ActiveTourneyWins_Coach (A & B)\n",
    "- NCAATourneySeed (A & B)\n",
    "- ActiveAPRank (A & B)\n",
    "- ActivePOMRank (A & B)\n",
    "- ActiveNETRank (A & B)\n",
    "- SeasonBestAPRank (A & B)\n",
    "- SeasonBestPOMRank (A & B)\n",
    "- All non zero-to-one average metrics (Self & Opponent, Overall & Last5, A & B)\n",
    "\n",
    "## Numeric variables (leave alone)\n",
    "- RollingWinPct (Self & Opponent, Overall & Last5, A & B)\n",
    "- RollingP5WinPctOverall (Self & Opponent, A & B)\n",
    "- RollingNP5WinPctOverall (Self & Opponent, A & B)\n",
    "- FreeThrowPct (Self & Opponent, Overall & Last5, A & B)\n",
    "- ThreePtPct (Self & Opponent, Overall & Last5, A & B)\n",
    "- FieldGoalPct (Self & Opponent, Overall & Last5, A & B)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets\n",
    "X, y = data.drop([\"WinFlag_A\"]), data[\"WinFlag_A\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, random_state=SEED, stratify = X['NCAATourneyFlag_A'])\n",
    "\n",
    "train_weights = X_train.with_columns(\n",
    "    pl.when(pl.col(\"Season\") == 2025).then(pl.lit(2)).otherwise(pl.lit(1)).alias(\"train_weights\")\n",
    ")['train_weights'].to_numpy()\n",
    "\n",
    "# Split up categorical variables...cv1: Subset to be one hot encoded. cv2: Subset to remain untouched.\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_train_1 = enc.fit_transform(X_train.select(['GameLocation_A','TeamConf_A','TeamConf_B','CoachName_A','CoachName_B','TeamID_A','TeamID_B','Season','NCAATourneySeed_A','NCAATourneySeed_B','ActiveTourneyWins_School_A','ActiveTourneyWins_School_B','ActiveTourneyWins_Coach_A','ActiveTourneyWins_Coach_B','ActiveAPRank_A','ActivePOMRank_A','ActiveNETRank_A','SeasonBestAPRank_A','SeasonBestPOMRank_A','ActiveAPRank_B','ActivePOMRank_B','ActiveNETRank_B','SeasonBestAPRank_B','SeasonBestPOMRank_B']))\n",
    "X_test_1 = enc.transform(X_test.select(['GameLocation_A','TeamConf_A','TeamConf_B','CoachName_A','CoachName_B','TeamID_A','TeamID_B','Season','NCAATourneySeed_A','NCAATourneySeed_B','ActiveTourneyWins_School_A','ActiveTourneyWins_School_B','ActiveTourneyWins_Coach_A','ActiveTourneyWins_Coach_B','ActiveAPRank_A','ActivePOMRank_A','ActiveNETRank_A','SeasonBestAPRank_A','SeasonBestPOMRank_A','ActiveAPRank_B','ActivePOMRank_B','ActiveNETRank_B','SeasonBestAPRank_B','SeasonBestPOMRank_B']))\n",
    "\n",
    "X_train_2 = X_train.select([\"RegSeasonFlag_A\",\"ConfTourneyFlag_A\",\"NCAATourneyFlag_A\"]).to_numpy()\n",
    "X_test_2 = X_test.select([\"RegSeasonFlag_A\",\"ConfTourneyFlag_A\",\"NCAATourneyFlag_A\"]).to_numpy()\n",
    "\n",
    "X_train_categorical = np.hstack((X_train_1, X_train_2))\n",
    "X_test_categorical = np.hstack((X_test_1, X_test_2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler_cols = [col for col in data.columns if re.match(r'.*Avg.*',col) != None]\n",
    "\n",
    "X_train_3 = scaler.fit_transform(X_train.select(scaler_cols))\n",
    "X_test_3 = scaler.transform(X_test.select(scaler_cols))\n",
    "\n",
    "X_train_4 = X_train.select([\"RollingWinPct_Overall_A\",\"RollingWinPct_Last5_A\",\"RollingP5WinPct_Overall_A\",\"RollingNP5WinPct_Overall_A\",\"FreeThrowPct_Overall_A\",\"FreeThrowPct_Last5_A\",\"OppFreeThrowPct_Overall_A\",\"OppFreeThrowPct_Last5_A\",\"FieldGoalPct_Overall_A\",\"FieldGoalPct_Last5_A\",\"OppFieldGoalPct_Overall_A\",\"OppFieldGoalPct_Last5_A\",\"ThreePtPct_Overall_A\",\"ThreePtPct_Last5_A\",\"OppThreePtPct_Overall_A\",\"OppThreePtPct_Last5_A\",\n",
    "                            \"RollingWinPct_Overall_B\",\"RollingWinPct_Last5_B\",\"RollingP5WinPct_Overall_B\",\"RollingNP5WinPct_Overall_B\",\"FreeThrowPct_Overall_B\",\"FreeThrowPct_Last5_B\",\"OppFreeThrowPct_Overall_B\",\"OppFreeThrowPct_Last5_B\",\"FieldGoalPct_Overall_B\",\"FieldGoalPct_Last5_B\",\"OppFieldGoalPct_Overall_B\",\"OppFieldGoalPct_Last5_B\",\"ThreePtPct_Overall_B\",\"ThreePtPct_Last5_B\",\"OppThreePtPct_Overall_B\",\"OppThreePtPct_Last5_B\"]).to_numpy()\n",
    "X_test_4 = X_test.select([\"RollingWinPct_Overall_A\",\"RollingWinPct_Last5_A\",\"RollingP5WinPct_Overall_A\",\"RollingNP5WinPct_Overall_A\",\"FreeThrowPct_Overall_A\",\"FreeThrowPct_Last5_A\",\"OppFreeThrowPct_Overall_A\",\"OppFreeThrowPct_Last5_A\",\"FieldGoalPct_Overall_A\",\"FieldGoalPct_Last5_A\",\"OppFieldGoalPct_Overall_A\",\"OppFieldGoalPct_Last5_A\",\"ThreePtPct_Overall_A\",\"ThreePtPct_Last5_A\",\"OppThreePtPct_Overall_A\",\"OppThreePtPct_Last5_A\",\n",
    "                            \"RollingWinPct_Overall_B\",\"RollingWinPct_Last5_B\",\"RollingP5WinPct_Overall_B\",\"RollingNP5WinPct_Overall_B\",\"FreeThrowPct_Overall_B\",\"FreeThrowPct_Last5_B\",\"OppFreeThrowPct_Overall_B\",\"OppFreeThrowPct_Last5_B\",\"FieldGoalPct_Overall_B\",\"FieldGoalPct_Last5_B\",\"OppFieldGoalPct_Overall_B\",\"OppFieldGoalPct_Last5_B\",\"ThreePtPct_Overall_B\",\"ThreePtPct_Last5_B\",\"OppThreePtPct_Overall_B\",\"OppThreePtPct_Last5_B\"]).to_numpy()\n",
    "\n",
    "X_train_numeric = np.hstack((X_train_3, X_train_4))\n",
    "X_test_numeric = np.hstack((X_test_3, X_test_4))\n",
    "#print(scaler_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model-ready input datasets\n",
    "X_train_final = np.hstack((X_train_categorical, X_train_numeric))\n",
    "X_test_final = np.hstack((X_test_categorical, X_test_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input variable dataset shape (train): (4219, 4474)\n",
      "Target variable shape (train): (4219,)\n",
      "Input variable dataset shape (test): (1809, 4474)\n",
      "Target variable shape (test): (1809,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Input variable dataset shape (train): {X_train_final.shape}\")\n",
    "print(f\"Target variable shape (train): {y_train.shape}\")\n",
    "print(f\"Input variable dataset shape (test): {X_test_final.shape}\")\n",
    "print(f\"Target variable shape (test): {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-17 18:10:20,838] A new study created in memory with name: no-name-1ca58c46-ef82-4ce9-9cf9-39fc6389c652\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:10:21,105] Trial 0 finished with value: 0.2340264937111996 and parameters: {'C': 6.558900787768207e-05, 'solver': 'liblinear'}. Best is trial 0 with value: 0.2340264937111996.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:10:21,797] Trial 1 finished with value: 0.29356114613766887 and parameters: {'C': 15.99917553970912, 'solver': 'liblinear'}. Best is trial 0 with value: 0.2340264937111996.\n",
      "[I 2025-03-17 18:10:34,218] Trial 2 finished with value: 0.31823083820558684 and parameters: {'C': 93.12330260039107, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.2340264937111996.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:10:34,353] Trial 3 finished with value: 0.2261280017271386 and parameters: {'C': 0.00013969215862233891, 'solver': 'liblinear'}. Best is trial 3 with value: 0.2261280017271386.\n",
      "[I 2025-03-17 18:10:42,087] Trial 4 finished with value: 0.30688801690187006 and parameters: {'C': 36.60242682072474, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.2261280017271386.\n",
      "[I 2025-03-17 18:10:49,109] Trial 5 finished with value: 0.3181759196331239 and parameters: {'C': 91.00752026512222, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.2261280017271386.\n",
      "[I 2025-03-17 18:10:56,016] Trial 6 finished with value: 0.2857167298980698 and parameters: {'C': 10.56487181384806, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.2261280017271386.\n",
      "[I 2025-03-17 18:10:57,398] Trial 7 finished with value: 0.18756120803734488 and parameters: {'C': 0.026661683950170087, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:10:57,750] Trial 8 finished with value: 0.21832753403457283 and parameters: {'C': 0.7514297591963577, 'solver': 'liblinear'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:10:58,834] Trial 9 finished with value: 0.1880587301598178 and parameters: {'C': 0.01114202625532771, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:01,292] Trial 10 finished with value: 0.1889476846936104 and parameters: {'C': 0.007486417656762207, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:02,273] Trial 11 finished with value: 0.1882526203736365 and parameters: {'C': 0.010050026534424104, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:04,043] Trial 12 finished with value: 0.19591941157763818 and parameters: {'C': 0.1852627405353209, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:04,714] Trial 13 finished with value: 0.20009449761684434 and parameters: {'C': 0.0012691063524398387, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:06,013] Trial 14 finished with value: 0.18990225651189785 and parameters: {'C': 0.07769818406896642, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:06,556] Trial 15 finished with value: 0.20579549705938613 and parameters: {'C': 0.000736755613514593, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:09,907] Trial 16 finished with value: 0.23078344190627853 and parameters: {'C': 1.2588642497050482, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:11,033] Trial 17 finished with value: 0.18764527967165526 and parameters: {'C': 0.015374758800078516, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:11,168] Trial 18 finished with value: 0.24543984510473785 and parameters: {'C': 1.1284244758989498e-05, 'solver': 'liblinear'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:11,841] Trial 19 finished with value: 0.19819729081815857 and parameters: {'C': 0.0015573454603902497, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:14,333] Trial 20 finished with value: 0.20644333917605032 and parameters: {'C': 0.40930345909859944, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:15,549] Trial 21 finished with value: 0.18758195596848534 and parameters: {'C': 0.016908178782645746, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:18,024] Trial 22 finished with value: 0.18888921416458426 and parameters: {'C': 0.058748783404003746, 'solver': 'lbfgs'}. Best is trial 7 with value: 0.18756120803734488.\n",
      "[I 2025-03-17 18:11:19,201] Trial 23 finished with value: 0.18752922345173595 and parameters: {'C': 0.01916721856548597, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:19,984] Trial 24 finished with value: 0.19140121980915423 and parameters: {'C': 0.004070781112644821, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:23,916] Trial 25 finished with value: 0.2487217007516551 and parameters: {'C': 2.4943315574407032, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:26,515] Trial 26 finished with value: 0.1889422200935729 and parameters: {'C': 0.05983337512927064, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:26,667] Trial 27 finished with value: 0.18774838854205886 and parameters: {'C': 0.03257041914443166, 'solver': 'liblinear'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:27,203] Trial 28 finished with value: 0.21533720329957437 and parameters: {'C': 0.00033194172147902614, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:27,401] Trial 29 finished with value: 0.19658159615424403 and parameters: {'C': 0.19837866169820217, 'solver': 'liblinear'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:28,134] Trial 30 finished with value: 0.19277331816905183 and parameters: {'C': 0.0031924212187177015, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:29,261] Trial 31 finished with value: 0.18756268016292343 and parameters: {'C': 0.01736385348572308, 'solver': 'lbfgs'}. Best is trial 23 with value: 0.18752922345173595.\n",
      "[I 2025-03-17 18:11:30,515] Trial 32 finished with value: 0.18750947854492248 and parameters: {'C': 0.022665101668970695, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:32,165] Trial 33 finished with value: 0.19331041776093974 and parameters: {'C': 0.1382861529593374, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:32,310] Trial 34 finished with value: 0.18757225712544418 and parameters: {'C': 0.025015349705971468, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:33,081] Trial 35 finished with value: 0.19110152724168347 and parameters: {'C': 0.00431579079023429, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:34,881] Trial 36 finished with value: 0.21893793875070544 and parameters: {'C': 0.0002473566235203382, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:39,260] Trial 37 finished with value: 0.26050998691924715 and parameters: {'C': 3.8478366442897545, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:39,412] Trial 38 finished with value: 0.18782965226346662 and parameters: {'C': 0.03502742085069448, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:42,010] Trial 39 finished with value: 0.21347763379754287 and parameters: {'C': 0.595542611573167, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:42,522] Trial 40 finished with value: 0.23618145647720304 and parameters: {'C': 3.3710693497841565e-05, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:42,665] Trial 41 finished with value: 0.18755229497350112 and parameters: {'C': 0.022901212833276893, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:42,797] Trial 42 finished with value: 0.1894348033349223 and parameters: {'C': 0.006559676435338971, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:42,937] Trial 43 finished with value: 0.19440772570607845 and parameters: {'C': 0.002519158389419869, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:43,123] Trial 44 finished with value: 0.1934695710104532 and parameters: {'C': 0.1413246010513343, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:43,258] Trial 45 finished with value: 0.18797011025114627 and parameters: {'C': 0.012152450422901358, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:43,429] Trial 46 finished with value: 0.189564365019139 and parameters: {'C': 0.07155596073355812, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:43,988] Trial 47 finished with value: 0.2048215099020861 and parameters: {'C': 0.0008039961198966829, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:46,372] Trial 48 finished with value: 0.20448001035250224 and parameters: {'C': 0.363001401800536, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:47,617] Trial 49 finished with value: 0.1875364606596866 and parameters: {'C': 0.02518946582171217, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:48,753] Trial 50 finished with value: 0.18793572829276653 and parameters: {'C': 0.03817575641070793, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:49,667] Trial 51 finished with value: 0.189090252586905 and parameters: {'C': 0.007146567958192513, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:50,866] Trial 52 finished with value: 0.18760733929289478 and parameters: {'C': 0.016365971331762624, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:52,386] Trial 53 finished with value: 0.1916217224830501 and parameters: {'C': 0.10905727434008965, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:53,696] Trial 54 finished with value: 0.18751546570951166 and parameters: {'C': 0.024590067659048996, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:55,684] Trial 55 finished with value: 0.19999561356628595 and parameters: {'C': 0.26550150685549057, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:56,302] Trial 56 finished with value: 0.19702631100879786 and parameters: {'C': 0.0017812784270054872, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:57,100] Trial 57 finished with value: 0.18900494291594713 and parameters: {'C': 0.0073684242950875865, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 8.\n",
      "  warnings.warn(\n",
      "[I 2025-03-17 18:11:57,246] Trial 58 finished with value: 0.18788429718790686 and parameters: {'C': 0.03655921518001769, 'solver': 'liblinear'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:58,579] Trial 59 finished with value: 0.19047245202153895 and parameters: {'C': 0.08849186131890276, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:11:59,832] Trial 60 finished with value: 0.18753102729509843 and parameters: {'C': 0.024906319561666265, 'solver': 'lbfgs'}. Best is trial 32 with value: 0.18750947854492248.\n",
      "[I 2025-03-17 18:12:00,973] Trial 61 finished with value: 0.1875019231425411 and parameters: {'C': 0.021563761766018562, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:02,101] Trial 62 finished with value: 0.18751973485397092 and parameters: {'C': 0.019181424390243586, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:03,400] Trial 63 finished with value: 0.18868710227264432 and parameters: {'C': 0.05473558606443308, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:04,306] Trial 64 finished with value: 0.1881646971219822 and parameters: {'C': 0.01051851164955777, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:05,193] Trial 65 finished with value: 0.19035496385493655 and parameters: {'C': 0.005076324424481209, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:06,344] Trial 66 finished with value: 0.188561956752426 and parameters: {'C': 0.05229003392991567, 'solver': 'lbfgs'}. Best is trial 61 with value: 0.1875019231425411.\n",
      "[I 2025-03-17 18:12:07,644] Trial 67 finished with value: 0.18750008742374427 and parameters: {'C': 0.0216474637891819, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:08,704] Trial 68 finished with value: 0.18804470738190063 and parameters: {'C': 0.011208877983902257, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:09,359] Trial 69 finished with value: 0.19494027243083042 and parameters: {'C': 0.002317426323219131, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:10,018] Trial 70 finished with value: 0.20303222411162453 and parameters: {'C': 0.000948884462915235, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:11,384] Trial 71 finished with value: 0.1875065298838497 and parameters: {'C': 0.02123876401568625, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:12,564] Trial 72 finished with value: 0.18755915783548913 and parameters: {'C': 0.017733210694592424, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:13,671] Trial 73 finished with value: 0.1883343140836021 and parameters: {'C': 0.04734102288141023, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:14,876] Trial 74 finished with value: 0.1875114919033557 and parameters: {'C': 0.023351500553536474, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:15,652] Trial 75 finished with value: 0.19138446269160103 and parameters: {'C': 0.004083934430437061, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:16,716] Trial 76 finished with value: 0.18852128674786217 and parameters: {'C': 0.008885906570260284, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:18,406] Trial 77 finished with value: 0.19569318431223176 and parameters: {'C': 0.18170923661259133, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:19,764] Trial 78 finished with value: 0.1898535807363034 and parameters: {'C': 0.07685720790790007, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:20,921] Trial 79 finished with value: 0.18773705723333553 and parameters: {'C': 0.01410031044944307, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:21,732] Trial 80 finished with value: 0.1903373051087799 and parameters: {'C': 0.005097240702079103, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:23,015] Trial 81 finished with value: 0.18752128357906153 and parameters: {'C': 0.024121758626749725, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:24,426] Trial 82 finished with value: 0.1875269353434179 and parameters: {'C': 0.02496680302328415, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:25,571] Trial 83 finished with value: 0.18765434068325826 and parameters: {'C': 0.029819129684377395, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:27,057] Trial 84 finished with value: 0.19181011748289412 and parameters: {'C': 0.11224785413124543, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:28,120] Trial 85 finished with value: 0.18798084687561792 and parameters: {'C': 0.03897610503246697, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:29,183] Trial 86 finished with value: 0.18754268209478872 and parameters: {'C': 0.019842457824146977, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:30,114] Trial 87 finished with value: 0.1879394865130539 and parameters: {'C': 0.012046040761175906, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:30,988] Trial 88 finished with value: 0.1892191442730701 and parameters: {'C': 0.006853894351930942, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:31,709] Trial 89 finished with value: 0.19302297857261833 and parameters: {'C': 0.0030666686980980956, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:32,970] Trial 90 finished with value: 0.18994495352147608 and parameters: {'C': 0.07889448725681272, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:34,280] Trial 91 finished with value: 0.1875947185139673 and parameters: {'C': 0.02802591700831035, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:35,458] Trial 92 finished with value: 0.18753044032461058 and parameters: {'C': 0.01875457646111032, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:40,983] Trial 93 finished with value: 0.3128832110419464 and parameters: {'C': 57.80022315618987, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:42,083] Trial 94 finished with value: 0.18813101923403264 and parameters: {'C': 0.04300376557353094, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:43,196] Trial 95 finished with value: 0.18761443915842138 and parameters: {'C': 0.016123913975974877, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:44,112] Trial 96 finished with value: 0.188393828586839 and parameters: {'C': 0.009396950930925964, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:45,337] Trial 97 finished with value: 0.1890525722635509 and parameters: {'C': 0.0618491584761471, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:50,938] Trial 98 finished with value: 0.292776734035927 and parameters: {'C': 15.234717543622242, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n",
      "[I 2025-03-17 18:12:52,147] Trial 99 finished with value: 0.18753625954022857 and parameters: {'C': 0.024894123219043877, 'solver': 'lbfgs'}. Best is trial 67 with value: 0.18750008742374427.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.0216474637891819, 'solver': 'lbfgs'}\n",
      "0.18750008742374427\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression: l2 penalty\n",
    "def logistic_objective(trial):\n",
    "    C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs','liblinear'])\n",
    "    params = {'random_state':SEED, 'penalty': 'l2', 'C':C, 'solver':solver, 'n_jobs':-1, 'max_iter':1000}\n",
    "\n",
    "    mod = LogisticRegression(**params)\n",
    "    mod.fit(X = X_train_final, y = y_train)\n",
    "\n",
    "    y_pred = mod.predict_proba(X_test_final)[:,1]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(logistic_objective, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjurjevich/Desktop/personalProjects/march_madness/env/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression: l1 penalty\n",
    "def logistic_objective_2(trial):\n",
    "    C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    solver = trial.suggest_categorical('solver', ['liblinear','saga'])\n",
    "    params = {'random_state':SEED, 'penalty': 'l1', 'C':C, 'solver':solver, 'n_jobs':-1, 'max_iter':1000}\n",
    "\n",
    "    mod = LogisticRegression(**params)\n",
    "    mod.fit(X = X_train_final, y = y_train)\n",
    "\n",
    "    y_pred = mod.predict_proba(X_test_final)[:,1]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(logistic_objective_2, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression: elasticnet (both)\n",
    "def logistic_objective_3(trial):\n",
    "    C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
    "    l1_ratio = trial.suggest_float('l1_ratio', 0, 1)\n",
    "    params = {'random_state':SEED, 'l1_ratio':l1_ratio, 'penalty': 'elasticnet', 'C':C, 'solver':'saga', 'n_jobs':-1, 'max_iter':1000}\n",
    "\n",
    "    mod = LogisticRegression(**params)\n",
    "    mod.fit(X = X_train_final, y = y_train)\n",
    "\n",
    "    y_pred = mod.predict_proba(X_test_final)[:,1]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(logistic_objective_3, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "def rf_objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators',10,500)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split',2,20)\n",
    "    params = {'random_state': SEED, 'n_estimators':n_estimators, 'min_samples_split':min_samples_split, 'n_jobs':-1}\n",
    "\n",
    "    mod = RandomForestClassifier(**params)\n",
    "    mod.fit(X = X_train_final, y = y_train)\n",
    "\n",
    "    y_pred = mod.predict_proba(X_test_final)[:,1]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(rf_objective, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE NATIVE TENSORFLOW HYPERPARAMETER TUNING METHODS \n",
    "\n",
    "\n",
    "# Start with logistic regressio\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def nn_objective(trial):\n",
    "    neurons = trial.suggest_int('neurons',16,256)\n",
    "    learning_rate = trial.suggest_float('learning_rate',1e-5,1e-2)\n",
    "    dense_layers = trial.suggest_int('dense_layers',1,5)\n",
    "    #threshold = trial.suggest_float('threshold', 0, 1)\n",
    "\n",
    "    mod = Sequential([\n",
    "        Input(shape=(X_train_final.shape[1],))\n",
    "    ])\n",
    "    for _ in range(dense_layers):\n",
    "        mod.add(Dense(neurons, activation='relu'))\n",
    "    mod.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    mod.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics=['mse'])\n",
    "\n",
    "    mod.fit(X_train_final, y_train, epochs=10, batch_size=256, verbose=0)\n",
    "    y_pred = mod.predict(X_test_final).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(nn_objective, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-17 18:16:23,749] A new study created in memory with name: no-name-0925de75-7aef-4546-ab4e-03fd54a8d632\n",
      "[I 2025-03-17 18:16:37,686] Trial 0 finished with value: 0.19012500675873895 and parameters: {'C': 0.018505160166819416, 'n_estimators': 472, 'min_samples_split': 7}. Best is trial 0 with value: 0.19012500675873895.\n",
      "[I 2025-03-17 18:16:45,363] Trial 1 finished with value: 0.19036319213145617 and parameters: {'C': 0.010943151893460191, 'n_estimators': 470, 'min_samples_split': 5}. Best is trial 0 with value: 0.19012500675873895.\n",
      "[I 2025-03-17 18:16:51,164] Trial 2 finished with value: 0.19302665898813134 and parameters: {'C': 0.0018540739509317887, 'n_estimators': 305, 'min_samples_split': 10}. Best is trial 0 with value: 0.19012500675873895.\n",
      "[I 2025-03-17 18:16:56,704] Trial 3 finished with value: 0.19117528938574996 and parameters: {'C': 0.09520312474025192, 'n_estimators': 370, 'min_samples_split': 2}. Best is trial 0 with value: 0.19012500675873895.\n",
      "[I 2025-03-17 18:16:59,101] Trial 4 finished with value: 0.189845241729239 and parameters: {'C': 0.023763902096952318, 'n_estimators': 136, 'min_samples_split': 2}. Best is trial 4 with value: 0.189845241729239.\n",
      "[I 2025-03-17 18:17:05,817] Trial 5 finished with value: 0.19972564197360332 and parameters: {'C': 0.904610275895411, 'n_estimators': 367, 'min_samples_split': 9}. Best is trial 4 with value: 0.189845241729239.\n",
      "[I 2025-03-17 18:17:11,863] Trial 6 finished with value: 0.19319810157100037 and parameters: {'C': 0.002007794608645052, 'n_estimators': 447, 'min_samples_split': 2}. Best is trial 4 with value: 0.189845241729239.\n",
      "[I 2025-03-17 18:17:18,343] Trial 7 finished with value: 0.1896680410325244 and parameters: {'C': 0.04129242052362831, 'n_estimators': 498, 'min_samples_split': 10}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:22,236] Trial 8 finished with value: 0.19033956721957812 and parameters: {'C': 0.010956025436102282, 'n_estimators': 275, 'min_samples_split': 9}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:28,429] Trial 9 finished with value: 0.1945823324623192 and parameters: {'C': 0.2867227599975086, 'n_estimators': 324, 'min_samples_split': 8}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:31,243] Trial 10 finished with value: 0.20492675964962034 and parameters: {'C': 0.00011810406489906364, 'n_estimators': 193, 'min_samples_split': 5}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:33,182] Trial 11 finished with value: 0.19047337640670403 and parameters: {'C': 0.07130792732913858, 'n_estimators': 76, 'min_samples_split': 4}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:37,119] Trial 12 finished with value: 0.1911981739106883 and parameters: {'C': 0.07286994973029227, 'n_estimators': 127, 'min_samples_split': 3}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:40,365] Trial 13 finished with value: 0.19452301653386925 and parameters: {'C': 0.001517603425264218, 'n_estimators': 197, 'min_samples_split': 6}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:43,625] Trial 14 finished with value: 0.1908138154252031 and parameters: {'C': 0.03940590328230868, 'n_estimators': 226, 'min_samples_split': 7}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:45,910] Trial 15 finished with value: 0.19078320971392257 and parameters: {'C': 0.0038484126577615347, 'n_estimators': 138, 'min_samples_split': 10}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:51,282] Trial 16 finished with value: 0.19443485025551943 and parameters: {'C': 0.2905683128802459, 'n_estimators': 379, 'min_samples_split': 4}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:56,403] Trial 17 finished with value: 0.19959274490592688 and parameters: {'C': 0.0003768194315512103, 'n_estimators': 417, 'min_samples_split': 7}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:17:59,973] Trial 18 finished with value: 0.19034346091781246 and parameters: {'C': 0.022472957560154248, 'n_estimators': 257, 'min_samples_split': 3}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:03,081] Trial 19 finished with value: 0.19297430115591377 and parameters: {'C': 0.18682889589511523, 'n_estimators': 147, 'min_samples_split': 6}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:04,558] Trial 20 finished with value: 0.19141369590977414 and parameters: {'C': 0.004520879190777808, 'n_estimators': 76, 'min_samples_split': 9}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:10,584] Trial 21 finished with value: 0.19024808806563354 and parameters: {'C': 0.025250449152486382, 'n_estimators': 495, 'min_samples_split': 8}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:15,844] Trial 22 finished with value: 0.19020590469253246 and parameters: {'C': 0.017924504040538972, 'n_estimators': 426, 'min_samples_split': 7}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:21,962] Trial 23 finished with value: 0.19111744277037537 and parameters: {'C': 0.006468163130842005, 'n_estimators': 498, 'min_samples_split': 8}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:27,117] Trial 24 finished with value: 0.1906374392452047 and parameters: {'C': 0.06583089183102493, 'n_estimators': 399, 'min_samples_split': 5}. Best is trial 7 with value: 0.1896680410325244.\n",
      "[I 2025-03-17 18:18:32,745] Trial 25 finished with value: 0.18953867896875912 and parameters: {'C': 0.035600320017420875, 'n_estimators': 460, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:18:37,365] Trial 26 finished with value: 0.19154727492904405 and parameters: {'C': 0.1598483753450124, 'n_estimators': 344, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:18:43,532] Trial 27 finished with value: 0.19015990949157974 and parameters: {'C': 0.043649909667481994, 'n_estimators': 457, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:18:49,840] Trial 28 finished with value: 0.19687031895088136 and parameters: {'C': 0.6121302761452913, 'n_estimators': 427, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:18:55,707] Trial 29 finished with value: 0.19021900647654685 and parameters: {'C': 0.03548701506414034, 'n_estimators': 474, 'min_samples_split': 6}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:18:59,017] Trial 30 finished with value: 0.19073721387599232 and parameters: {'C': 0.014997553902483975, 'n_estimators': 241, 'min_samples_split': 8}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:04,713] Trial 31 finished with value: 0.19071574666878083 and parameters: {'C': 0.007330133278758707, 'n_estimators': 474, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:10,225] Trial 32 finished with value: 0.18984223765698874 and parameters: {'C': 0.010620203660287118, 'n_estimators': 443, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:16,166] Trial 33 finished with value: 0.18963791563325838 and parameters: {'C': 0.014509989117806845, 'n_estimators': 445, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:21,664] Trial 34 finished with value: 0.19182503379926505 and parameters: {'C': 0.0030296223589795263, 'n_estimators': 446, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:26,717] Trial 35 finished with value: 0.19568080830846216 and parameters: {'C': 0.0008515380572330024, 'n_estimators': 399, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:33,037] Trial 36 finished with value: 0.18993238537673024 and parameters: {'C': 0.010316755709441565, 'n_estimators': 497, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:38,824] Trial 37 finished with value: 0.19025555666132057 and parameters: {'C': 0.012095943247477196, 'n_estimators': 466, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:43,554] Trial 38 finished with value: 0.19141672428301804 and parameters: {'C': 0.1517923561222838, 'n_estimators': 349, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:49,076] Trial 39 finished with value: 0.19002327598934404 and parameters: {'C': 0.03254392853705377, 'n_estimators': 442, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:54,001] Trial 40 finished with value: 0.19123895701464608 and parameters: {'C': 0.006884153006321382, 'n_estimators': 397, 'min_samples_split': 8}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:19:59,842] Trial 41 finished with value: 0.19000960313759185 and parameters: {'C': 0.01889533757584508, 'n_estimators': 480, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:20:03,985] Trial 42 finished with value: 0.19027664089396248 and parameters: {'C': 0.04833073006990484, 'n_estimators': 292, 'min_samples_split': 2}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:20:09,561] Trial 43 finished with value: 0.1908903624640068 and parameters: {'C': 0.1145397027846804, 'n_estimators': 443, 'min_samples_split': 10}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:20:13,563] Trial 44 finished with value: 0.1901142213457757 and parameters: {'C': 0.02482553158216769, 'n_estimators': 307, 'min_samples_split': 9}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:20:16,151] Trial 45 finished with value: 0.19045150649563475 and parameters: {'C': 0.06788691296210614, 'n_estimators': 172, 'min_samples_split': 4}. Best is trial 25 with value: 0.18953867896875912.\n",
      "[I 2025-03-17 18:20:17,847] Trial 46 finished with value: 0.18947725963405862 and parameters: {'C': 0.013207489409031678, 'n_estimators': 99, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:22,830] Trial 47 finished with value: 0.19213068718762147 and parameters: {'C': 0.0026287922808298707, 'n_estimators': 411, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:27,594] Trial 48 finished with value: 0.1905170333752188 and parameters: {'C': 0.005482268895437925, 'n_estimators': 375, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:29,191] Trial 49 finished with value: 0.19470763611370182 and parameters: {'C': 0.001249779373315106, 'n_estimators': 95, 'min_samples_split': 9}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:34,765] Trial 50 finished with value: 0.18966561498332804 and parameters: {'C': 0.013018486004190335, 'n_estimators': 457, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:40,497] Trial 51 finished with value: 0.1899272841651654 and parameters: {'C': 0.00935025158228124, 'n_estimators': 459, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:46,218] Trial 52 finished with value: 0.18979241647870687 and parameters: {'C': 0.011599187188055003, 'n_estimators': 482, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:52,014] Trial 53 finished with value: 0.1901185535387143 and parameters: {'C': 0.014250491080153763, 'n_estimators': 484, 'min_samples_split': 9}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:20:57,594] Trial 54 finished with value: 0.19000098200289856 and parameters: {'C': 0.027488215602599272, 'n_estimators': 464, 'min_samples_split': 9}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:21:03,002] Trial 55 finished with value: 0.1897750937773251 and parameters: {'C': 0.05205435677266272, 'n_estimators': 432, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:21:08,198] Trial 56 finished with value: 0.18972609451184536 and parameters: {'C': 0.048778426779540945, 'n_estimators': 419, 'min_samples_split': 10}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:21:12,888] Trial 57 finished with value: 0.19113283048685353 and parameters: {'C': 0.08971584945945879, 'n_estimators': 353, 'min_samples_split': 9}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:21:18,409] Trial 58 finished with value: 0.19475719024376112 and parameters: {'C': 0.3083609701913329, 'n_estimators': 412, 'min_samples_split': 8}. Best is trial 46 with value: 0.18947725963405862.\n",
      "[I 2025-03-17 18:21:21,183] Trial 59 finished with value: 0.18928812417215515 and parameters: {'C': 0.034646354824957495, 'n_estimators': 192, 'min_samples_split': 10}. Best is trial 59 with value: 0.18928812417215515.\n",
      "[I 2025-03-17 18:21:24,032] Trial 60 finished with value: 0.18998583781094555 and parameters: {'C': 0.018509359675101773, 'n_estimators': 206, 'min_samples_split': 9}. Best is trial 59 with value: 0.18928812417215515.\n",
      "[I 2025-03-17 18:21:26,328] Trial 61 finished with value: 0.18924656444580212 and parameters: {'C': 0.053294934440234185, 'n_estimators': 115, 'min_samples_split': 10}. Best is trial 61 with value: 0.18924656444580212.\n",
      "[I 2025-03-17 18:21:28,299] Trial 62 finished with value: 0.1890166866497362 and parameters: {'C': 0.029876830986284575, 'n_estimators': 117, 'min_samples_split': 10}. Best is trial 62 with value: 0.1890166866497362.\n",
      "[I 2025-03-17 18:21:30,207] Trial 63 finished with value: 0.18899149472146098 and parameters: {'C': 0.029817784326631003, 'n_estimators': 112, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:32,290] Trial 64 finished with value: 0.18904259508669863 and parameters: {'C': 0.03821172924031219, 'n_estimators': 114, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:34,687] Trial 65 finished with value: 0.1899186188324735 and parameters: {'C': 0.09122029267056245, 'n_estimators': 115, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:37,043] Trial 66 finished with value: 0.19003849968995415 and parameters: {'C': 0.03290260771085595, 'n_estimators': 154, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:39,357] Trial 67 finished with value: 0.18955168761885993 and parameters: {'C': 0.06425760917896266, 'n_estimators': 108, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:41,847] Trial 68 finished with value: 0.19084371093195288 and parameters: {'C': 0.11548987358360276, 'n_estimators': 97, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:43,910] Trial 69 finished with value: 0.18987791066241622 and parameters: {'C': 0.028983613604425147, 'n_estimators': 128, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:46,313] Trial 70 finished with value: 0.1892199365523285 and parameters: {'C': 0.022101686577172226, 'n_estimators': 160, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:48,781] Trial 71 finished with value: 0.18916898026202209 and parameters: {'C': 0.01988004944963975, 'n_estimators': 169, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:51,117] Trial 72 finished with value: 0.18927696062038857 and parameters: {'C': 0.018866482666306555, 'n_estimators': 155, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:53,436] Trial 73 finished with value: 0.1891703623880429 and parameters: {'C': 0.02203437322468304, 'n_estimators': 166, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:55,878] Trial 74 finished with value: 0.18920797270261872 and parameters: {'C': 0.020562511302777215, 'n_estimators': 161, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:21:58,278] Trial 75 finished with value: 0.19006421836785414 and parameters: {'C': 0.021918098802679697, 'n_estimators': 166, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:00,294] Trial 76 finished with value: 0.20375441217680507 and parameters: {'C': 0.00011330204295512993, 'n_estimators': 141, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:02,468] Trial 77 finished with value: 0.1892647771655063 and parameters: {'C': 0.045021727988743654, 'n_estimators': 125, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:05,019] Trial 78 finished with value: 0.19058876543696468 and parameters: {'C': 0.008244188293842688, 'n_estimators': 181, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:06,694] Trial 79 finished with value: 0.1906723606803166 and parameters: {'C': 0.021657095533419168, 'n_estimators': 84, 'min_samples_split': 8}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:09,855] Trial 80 finished with value: 0.18975579984523955 and parameters: {'C': 0.05805523973661279, 'n_estimators': 221, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:11,870] Trial 81 finished with value: 0.1891911191398986 and parameters: {'C': 0.042531630661428524, 'n_estimators': 119, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:14,050] Trial 82 finished with value: 0.18911635724790365 and parameters: {'C': 0.03946795360515054, 'n_estimators': 118, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:16,179] Trial 83 finished with value: 0.18910281363584686 and parameters: {'C': 0.024796097536130168, 'n_estimators': 133, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:18,376] Trial 84 finished with value: 0.19002991778657335 and parameters: {'C': 0.038446157169069954, 'n_estimators': 134, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:20,599] Trial 85 finished with value: 0.18917618162933753 and parameters: {'C': 0.016712148701953717, 'n_estimators': 145, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:22,836] Trial 86 finished with value: 0.19100412632691052 and parameters: {'C': 0.016034067024558417, 'n_estimators': 146, 'min_samples_split': 7}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:24,789] Trial 87 finished with value: 0.18902782446002922 and parameters: {'C': 0.02845714980083044, 'n_estimators': 122, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:26,520] Trial 88 finished with value: 0.19076420469554503 and parameters: {'C': 0.02528013362392747, 'n_estimators': 86, 'min_samples_split': 3}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:28,845] Trial 89 finished with value: 0.1905420669682412 and parameters: {'C': 0.07881874132568721, 'n_estimators': 107, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:31,435] Trial 90 finished with value: 0.1892267456255443 and parameters: {'C': 0.028899674454614593, 'n_estimators': 178, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:33,524] Trial 91 finished with value: 0.19044044122961978 and parameters: {'C': 0.039319158076325224, 'n_estimators': 121, 'min_samples_split': 5}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:35,639] Trial 92 finished with value: 0.18909516529479095 and parameters: {'C': 0.016931289623938868, 'n_estimators': 136, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:37,850] Trial 93 finished with value: 0.18954090978918747 and parameters: {'C': 0.008999013457267625, 'n_estimators': 135, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:39,656] Trial 94 finished with value: 0.18903039542578412 and parameters: {'C': 0.0259992626151283, 'n_estimators': 107, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:41,539] Trial 95 finished with value: 0.1891603307730957 and parameters: {'C': 0.031183031826603452, 'n_estimators': 105, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:42,999] Trial 96 finished with value: 0.20278662876029613 and parameters: {'C': 0.0001606551539191589, 'n_estimators': 87, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:44,887] Trial 97 finished with value: 0.18980206611052444 and parameters: {'C': 0.030433089126143325, 'n_estimators': 107, 'min_samples_split': 9}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:46,488] Trial 98 finished with value: 0.18955264857592075 and parameters: {'C': 0.026609797704298624, 'n_estimators': 75, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n",
      "[I 2025-03-17 18:22:48,583] Trial 99 finished with value: 0.18962238920290864 and parameters: {'C': 0.060753928692469185, 'n_estimators': 101, 'min_samples_split': 10}. Best is trial 63 with value: 0.18899149472146098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.029817784326631003, 'n_estimators': 112, 'min_samples_split': 10}\n",
      "0.18899149472146098\n"
     ]
    }
   ],
   "source": [
    "# Start with logistic regression\n",
    "def ensemble_objective_1(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 1, log=True)\n",
    "    log_kwargs = {'C':C, 'n_jobs': -1, 'random_state':SEED, 'max_iter':1000}\n",
    "\n",
    "    n_estimators = trial.suggest_int('n_estimators',75, 500)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    rf_kwargs = {'n_estimators': n_estimators, 'min_samples_split': min_samples_split, 'n_jobs': -1, 'random_state':SEED}\n",
    "\n",
    "\n",
    "    mod = VotingClassifier(estimators=[('rf', RandomForestClassifier(**rf_kwargs)),\n",
    "                                       ('lr',LogisticRegression(**log_kwargs))], \n",
    "                            voting='soft', \n",
    "                            n_jobs=-1)\n",
    "    mod.fit(X = X_train_final, y = y_train, sample_weight = train_weights)\n",
    "\n",
    "    y_pred = mod.predict_proba(X_test_final)[:,1]\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "study = optuna.create_study(direction = 'minimize')\n",
    "study.optimize(ensemble_objective_1, n_trials = 100)\n",
    "\n",
    "print(study.best_params)\n",
    "print(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Go with voting regressor containing random forest and logistic regression with optimized hyperparameters\n",
    "params = {'random_state':SEED, \n",
    "          'penalty': 'l2', \n",
    "          'C':0.0216474637891819, \n",
    "          'solver':'lbfgs', \n",
    "          'n_jobs':-1, \n",
    "          'max_iter':1000}\n",
    "\n",
    "model = LogisticRegression(**params).fit(X = X_train_final, y = y_train)\n",
    "\n",
    "# Export scaler, encoder, and model for dashboard use.\n",
    "joblib.dump(model, 'ensemble_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(enc, 'encoder.joblib')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
